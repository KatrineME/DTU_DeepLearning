{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Project9_U-Net_Algorithm_batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatrineME/DTU_DeepLearning/blob/main/DL_Project9_U_Net_Algorithm_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYiASafAXiM"
      },
      "source": [
        "# U-Net Algorithm\n",
        "Pixelwise segmentation for medical images - Cellari\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WPLzFAT-uPv"
      },
      "source": [
        "# Import & setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixPJ61zpAMwW"
      },
      "source": [
        "#Mount google drive for dataloading\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Deep')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuwwI28bA3ie"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "import torch\n",
        "import re\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.measure import label\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "\n",
        "#import sys\n",
        "#sys.path.append(os.path.join('.', '..')) # Allow us to import shared custom \n",
        "#                                         # libraries, like utils.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9Kp1sRSBCbt"
      },
      "source": [
        "# Data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC2V5eKTA9Nr"
      },
      "source": [
        "image_paths = glob.glob(\"/content/drive/My Drive/Deep/Warwick/*.bmp\") # if your path to the \n",
        "print(\"Total Observations:\\t\", len(image_paths))\n",
        "\n",
        "# now loading the train\n",
        "train_anno = np.sort(glob.glob(\"/content/drive/My Drive/Deep/Warwick/train_*[0-9]_anno.bmp\"))\n",
        "train_img  = np.sort(glob.glob(\"/content/drive/My Drive/Deep/Warwick/train_*[0-9].bmp\"))\n",
        "print(\"Total Observations_img:\\t\", len(train_img))\n",
        "print(\"Total Observations_anno:\\t\", len(train_anno))\n",
        "\n",
        "# now loading the test\n",
        "test_anno = np.sort(glob.glob(\"/content/drive/My Drive/Deep/Warwick/test*_*[0-9]_anno.bmp\"))\n",
        "test_img = np.sort(glob.glob(\"/content/drive/My Drive/Deep/Warwick/test*[0-9].bmp\"))\n",
        "print(\"Total Observations_img:\\t\", len(test_img))\n",
        "print(\"Total Observations_anno:\\t\", len(test_anno))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYySoGUFMiEW"
      },
      "source": [
        "#Ordering of data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia8pLh88Ml-U"
      },
      "source": [
        "# Training\n",
        "train_a_list = [0]*len(train_anno)\n",
        "train_i_list = [0]*len(train_img)\n",
        "\n",
        "for i in range(0,len(train_anno)):\n",
        "  a = int(re.findall(r'[0-9]+',train_anno[i])[0])\n",
        "  train_a_list[i] = a\n",
        "\n",
        "  m = int(re.findall(r'[0-9]+',train_img[i])[0])\n",
        "  train_i_list[i] = m  \n",
        "\n",
        "print(\"Train anno: \",train_a_list)\n",
        "print(\"Train image: \",train_i_list)\n",
        "\n",
        "# Test\n",
        "test_a_list = [0]*len(test_anno)\n",
        "test_i_list = [0]*len(test_img)\n",
        "\n",
        "for i in range(0,len(test_anno)):\n",
        "  if i > 59:  \n",
        "    a = int(re.findall(r'[0-9]+',test_anno[i])[0])\n",
        "    test_a_list[i] = a+60\n",
        "\n",
        "    m = int(re.findall(r'[0-9]+',test_img[i])[0])\n",
        "    test_i_list[i] = m+60\n",
        "\n",
        "  else:\n",
        "    a = int(re.findall(r'[0-9]+',test_anno[i])[0])\n",
        "    test_a_list[i] = a\n",
        "\n",
        "    m = int(re.findall(r'[0-9]+',test_img[i])[0])\n",
        "    test_i_list[i] = m\n",
        "\n",
        "#print(\"Test anno: \",test_a_list)\n",
        "#print(\"Test image: \",test_i_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1oSD8PqMpfL"
      },
      "source": [
        "img_train_order  = [0]*len(train_img)\n",
        "anno_train_order = [0]*len(train_anno)\n",
        "\n",
        "for i in range(0,len(train_i_list)):\n",
        "    for j in range(0,len(train_a_list)):\n",
        "        if train_i_list[i] == train_a_list[j]:\n",
        "           #print('i=',i,'j=',j)\n",
        "           img_train_order[i]  =  train_img[i]\n",
        "           anno_train_order[i] =  train_anno[j]\n",
        "        else:\n",
        "          1+1 # just something\n",
        "    #print(img_train_order[i])\n",
        "    #print(anno_train_order[i])\n",
        "\n",
        "img_test_order  = [0]*len(test_img)\n",
        "anno_test_order = [0]*len(test_anno)\n",
        "\n",
        "for i in range(0,len(test_i_list)):\n",
        "    for j in range(0,len(test_a_list)):\n",
        "        if test_i_list[i] == test_a_list[j]:\n",
        "           #print('i=',i,'j=',j)\n",
        "           img_test_order[i]  =  test_img[i]\n",
        "           anno_test_order[i] =  test_anno[j]\n",
        "        else:\n",
        "          1+1 # just something\n",
        "    #print(img_test_order[i])\n",
        "    #print(anno_test_order[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hEkBTtcCXJE"
      },
      "source": [
        "#Overall mean and std"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc9udB92CZKZ"
      },
      "source": [
        "mt   = torch.empty(len(train_img),3)\n",
        "st   = torch.empty(len(train_img),3)\n",
        "\n",
        "for i in range(0,len(train_img)):\n",
        "    im = np.uint8(Image.open(train_img[i]))\n",
        "\n",
        "    m  = np.mean(im,axis=(0,1))\n",
        "    mt[i,:] = Tensor(m)\n",
        "\n",
        "    s  = np.std(im,axis=(0,1))\n",
        "    st[i,:] = Tensor(s)\n",
        "\n",
        "overall_mean = torch.mean(mt,0)\n",
        "overall_std  = torch.mean(st,0)\n",
        "\n",
        "print('mean= ',overall_mean,'std= ',overall_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7OtTkfoypdh"
      },
      "source": [
        "# Batch Generator \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YF8CcLNytZG"
      },
      "source": [
        "# Random images: Amount of images\n",
        "amount = 85\n",
        "image_sample = [0]*amount #torch.empty(amount,1)\n",
        "anno_sample  = [0]*amount  #torch.empty(amount,1)\n",
        "\n",
        "#index = np.random.choice(list(range(0,85)), amount, replace=False)\n",
        "index = list(range(0,85))\n",
        "\n",
        "for k,h in enumerate(index):\n",
        "    image_sample[k] = img_train_order[h]\n",
        "    anno_sample[k]  = anno_train_order[h]\n",
        "#image_sample = np.random.choice(train_img, amount, replace = False)\n",
        "\n",
        "plt.figure(figsize=(30,30))\n",
        "\n",
        "imgt  = torch.empty(amount,512,512,3)\n",
        "annot = torch.empty(amount,2,512,512)\n",
        "imt  = torch.empty(amount,512,512,3)\n",
        "mt   = torch.empty(amount,3)\n",
        "st   = torch.empty(amount,3)\n",
        "\n",
        "#plt.figure(figsize=(20,20))\n",
        "# NORMALIZATION OF DATA\n",
        "for i in range(0,amount):\n",
        "    im  = Tensor(np.uint8(Image.open(image_sample[i])))\n",
        "    img = (im-overall_mean)/overall_std\n",
        "    imt = resize(img, output_shape=(512,512))\n",
        "    imgt[i,:,:,:]= Tensor(imt)\n",
        "\n",
        "    anno = np.uint8(Image.open(anno_sample[i]))\n",
        "    anno = resize(anno, output_shape=(512,512))\n",
        "    (_, anno) = cv2.threshold(anno, 0, 1, cv2.THRESH_BINARY)\n",
        "    anno = Tensor(anno)\n",
        "    anno = torch.nn.functional.one_hot(anno.to(torch.int64), num_classes=-1)\n",
        "    anno = anno.permute(2,0,1).float()\n",
        "    annot[i,:,:,:] = Tensor(anno)\n",
        "\n",
        "    #plt.subplot(2,amount, i+1)\n",
        "    #plt.imshow(imgt[i,:,:,:])\n",
        "    #plt.title(image_sample[i])\n",
        "\n",
        "    #plt.subplot(2,amount, i+amount+1)\n",
        "    #plt.imshow(annot[i,1,:,:])\n",
        "    #plt.title(image_sample[i])\n",
        "\n",
        "plt.subplot(1,2, 1)\n",
        "plt.imshow(imgt[34,:,:,:])\n",
        "plt.title(image_sample[34])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(annot[34,1,:,:])\n",
        "plt.title(image_sample[34])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_cUgDgQ8S_p"
      },
      "source": [
        "#TrainLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_tjZyJBAg5u"
      },
      "source": [
        "data   = np.uint8(imgt.permute(0, 3, 1, 2))\r\n",
        "labels = np.uint8(annot.permute(0,2,3,1))\r\n",
        "labels = labels[:,:,:,1]   # selecting layer with cell=1 and background=0\r\n",
        "trainset = list(zip(data,labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xFhIdis8SGf"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=6,\r\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vadf9O1jU7IS"
      },
      "source": [
        "print(\"# Training data\")\r\n",
        "print(\"Number of points:\", len(trainset))\r\n",
        "x, y = next(iter(trainloader))\r\n",
        "print(\"Batch dimension [B x C x H x W]:\", x.shape)\r\n",
        "print(\"Number of distinct labels:\", len(np.unique(trainset[0][1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvdnXHQ9We-Q"
      },
      "source": [
        "train_data_iter = iter(trainloader)\r\n",
        "images, labels = train_data_iter.next()\r\n",
        "\r\n",
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6iOLcTcoHp3"
      },
      "source": [
        "\r\n",
        "#U-net architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEdKcWvbUSx"
      },
      "source": [
        "from torch.nn import Linear, LSTM, Conv2d, ConvTranspose2d, Dropout, MaxPool2d, BatchNorm1d, BatchNorm2d, CrossEntropyLoss\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "height, width, channels = [512, 512, 3]\n",
        "\n",
        "filters       = 64\n",
        "kernel_size1  = 3\n",
        "kernel_size2  = 3\n",
        "\n",
        "conv_stride1  = 1\n",
        "conv_stride2  = 2\n",
        "\n",
        "conv_pad1     = 1\n",
        "conv_pad2     = 1\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Encoder (Contracting path)\n",
        "        self.conv_1 = Conv2d(in_channels = channels,\n",
        "                             out_channels = filters,\n",
        "                             kernel_size = kernel_size1,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad1)\n",
        "\n",
        "        self.conv_2 = Conv2d(in_channels = filters,\n",
        "                             out_channels = filters*2,\n",
        "                             kernel_size = kernel_size1,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad1)\n",
        "        \n",
        "        self.conv_3 = Conv2d(in_channels = filters*2,\n",
        "                             out_channels = filters*4,\n",
        "                             kernel_size = kernel_size1,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad1)\n",
        "        \n",
        "        self.conv_4 = Conv2d(in_channels = filters*4,\n",
        "                             out_channels = filters*8,\n",
        "                             kernel_size = kernel_size1,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad1)\n",
        "        \n",
        "        # Middle \n",
        "        self.conv_m = Conv2d(in_channels = filters*8,\n",
        "                             out_channels = filters*16,\n",
        "                             kernel_size = kernel_size1,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad1)\n",
        "        \n",
        "\n",
        "        # Decoder (Expansive path) - Transpose \n",
        "        self.conv_trans_4 = ConvTranspose2d(in_channels = filters*16,\n",
        "                             out_channels = filters*8,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride2,\n",
        "                             padding = conv_pad2,\n",
        "                             output_padding=1)\n",
        "        \n",
        "        self.conv_de_4 = Conv2d(in_channels = filters*16,\n",
        "                             out_channels = filters*8,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad2)\n",
        "         \n",
        "        self.conv_trans_3 = ConvTranspose2d(in_channels = filters*8,\n",
        "                             out_channels = filters*4,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride2,\n",
        "                             padding = conv_pad2, \n",
        "                             output_padding=1)\n",
        "        \n",
        "        self.conv_de_3 = Conv2d(in_channels = filters*8,\n",
        "                             out_channels = filters*4,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad2)\n",
        "        \n",
        "        self.conv_trans_2 = ConvTranspose2d(in_channels = filters*4,\n",
        "                             out_channels = filters*2,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride2,\n",
        "                             padding = conv_pad2, \n",
        "                             output_padding=1)\n",
        "        \n",
        "        self.conv_de_2 = Conv2d(in_channels = filters*4,\n",
        "                             out_channels = filters*2,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad2)\n",
        "        \n",
        "        self.conv_trans_1 = ConvTranspose2d(in_channels = filters*2,\n",
        "                             out_channels = filters*1,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride2,\n",
        "                             padding = conv_pad2, \n",
        "                             output_padding=1)\n",
        "        \n",
        "        self.conv_de_1 = Conv2d(in_channels = filters*2,\n",
        "                             out_channels = filters*1,\n",
        "                             kernel_size = kernel_size2,\n",
        "                             stride = conv_stride1,\n",
        "                             padding = conv_pad2)\n",
        "        \n",
        "        # Output layer \n",
        "        self.conv_out = Conv2d(in_channels = filters*1,\n",
        "                             out_channels = 2,\n",
        "                             kernel_size = 1,\n",
        "                             stride = 1,\n",
        "                             padding = 0)\n",
        "         \n",
        "        # Max pooling\n",
        "        self.maxp = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "    def forward(self, x_img):\n",
        "        #print(\"Initial image:\", x_img.shape)\n",
        "        \n",
        "        ## Contracting Convolutional layer ##\n",
        "        x_img_1 = self.conv_1(x_img)\n",
        "        x_img_1 = relu(x_img_1)\n",
        "        max_x_img_1 = self.maxp(x_img_1)\n",
        "        #print(\"x 1\", x_img_1.shape)\n",
        "        #print(\"After 1\", max_x_img_1.shape)\n",
        "\n",
        "        x_img_2 = self.conv_2(max_x_img_1)\n",
        "        x_img_2 = relu(x_img_2)\n",
        "        max_x_img_2 = self.maxp(x_img_2)\n",
        "        #print(\"x 2\", x_img_2.shape)\n",
        "        #print(\"After 2\", max_x_img_2.shape)\n",
        "\n",
        "        x_img_3 = self.conv_3(max_x_img_2)\n",
        "        x_img_3 = relu(x_img_3)\n",
        "        max_x_img_3 = self.maxp(x_img_3)\n",
        "        #print(\"x 3\", x_img_3.shape)\n",
        "        #print(\"After 3\", max_x_img_3.shape)\n",
        "\n",
        "        x_img_4 = self.conv_4(max_x_img_3)\n",
        "        x_img_4 = relu(x_img_4)\n",
        "        max_x_img_4 = self.maxp(x_img_4)\n",
        "        #print(\"x 4\", x_img_4.shape)\n",
        "        #print(\"After 4\", max_x_img_4.shape)\n",
        "\n",
        "        ## Middle layer ## \n",
        "        x_img_m = self.conv_m(max_x_img_4)\n",
        "        x_img_m = relu(x_img_m)\n",
        "        #print(\"X middle:\", x_img_m.shape)\n",
        "        \n",
        "        ## Expansive Convolutional layer ##\n",
        "        x_img_t4 = self.conv_trans_4(x_img_m)\n",
        "        x_img_t4 = torch.cat((x_img_t4, x_img_4), dim=1)\n",
        "        x_img_t4 = self.conv_de_4(x_img_t4)\n",
        "        x_img_t4 = relu(x_img_t4)\n",
        "        #print(\"Final 4\", x_img_t4.shape)\n",
        "  \n",
        "        x_img_t3 = self.conv_trans_3(x_img_t4)\n",
        "        x_img_t3 = torch.cat((x_img_t3, x_img_3),dim=1)\n",
        "        x_img_t3 = self.conv_de_3(x_img_t3)\n",
        "        x_img_t3 = relu(x_img_t3)\n",
        "        #print(\"Final 3:\", x_img_t3.shape)\n",
        "\n",
        "        x_img_t2 = self.conv_trans_2(x_img_t3)\n",
        "        x_img_t2 = torch.cat((x_img_t2, x_img_2),dim=1)\n",
        "        x_img_t2 = self.conv_de_2(x_img_t2)\n",
        "        x_img_t2 = relu(x_img_t2)\n",
        "        #print(\"Final 2:\", x_img_t2.shape)\n",
        "\n",
        "        x_img_t1 = self.conv_trans_1(x_img_t2)\n",
        "        x_img_t1 = torch.cat((x_img_t1, x_img_1),dim=1)\n",
        "        x_img_t1 = self.conv_de_1(x_img_t1)\n",
        "        x_img_t1 = relu(x_img_t1)\n",
        "        #print(\"Final 1:\", x_img_t1.shape)\n",
        "\n",
        "        x_img_out = self.conv_out(x_img_t1)\n",
        "        #x_img_out = softmax(x_img_out)\n",
        "        x_img_out = sigmoid(x_img_out)\n",
        "        #print(\"Train samples ximgtout:\", x_img_out.shape)\n",
        "\n",
        "        return x_img_out\n",
        "\n",
        "net = Net()\n",
        "#print(net)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-IbcoJyXwh1"
      },
      "source": [
        "# Training parameter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpzFy9Xe8Oe5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "LEARNING_RATE = 0.001 \n",
        "#criterion    = nn.CrossEntropyLoss() \n",
        "criterion     = nn.BCELoss()\n",
        "\n",
        "# weight_decay is equal to L2 regularization\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb-aRPpgQdZ_"
      },
      "source": [
        "#Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExC9H5T8-3Qh"
      },
      "source": [
        "num_epoch = 3 # Your code here!\n",
        "#trainloader = imgt.permute(0, 3, 1, 2)\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    print('Epoch=',epoch)\n",
        "    running_loss = 0.0  \n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        #inputs = trainloader\n",
        "        #labels = annot\n",
        "\n",
        "        print('i=',i)\n",
        "\n",
        "        # wrap them in Variable\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        labels = labels.float()\n",
        "        inputs = inputs.float()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        # Your code here!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # Your code here!\n",
        "        output = net(inputs)\n",
        "\n",
        "        #output = np.squeeze(output)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss\n",
        "        #print(loss)\n",
        "        #print(running_loss)\n",
        "\n",
        "        losses.append(running_loss)\n",
        "        #if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "        #print('[%d, %5d] loss: %.3f' %\n",
        "        (epoch + 1, i + 1, running_loss)\n",
        "        running_loss = 0.0\n",
        "\n",
        "epochs = np.arange(len(losses))\n",
        "plt.figure()\n",
        "plt.plot(epochs, losses, 'r', label='Training loss ',)\n",
        "\n",
        "# OBS MAKE LOSS PLOT\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv5n-O9XfzIL"
      },
      "source": [
        "#Normalize function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs4cU7pgf5CN"
      },
      "source": [
        "def Normal(image, annotation):\n",
        "    im  = Tensor(np.uint8(Image.open(image)))\n",
        "    img = (im-overall_mean)/overall_std\n",
        "    imt = resize(img, output_shape=(512,512))\n",
        "    imt = np.expand_dims(imt,axis=0)\n",
        "    image_n = Tensor(imt)\n",
        "\n",
        "    anno = np.uint8(Image.open(annotation))\n",
        "    anno = resize(anno, output_shape=(512,512))\n",
        "    (_, anno) = cv2.threshold(anno, 0, 1, cv2.THRESH_BINARY)\n",
        "    anno = Tensor(anno)\n",
        "    anno = torch.nn.functional.one_hot(anno.to(torch.int64), num_classes=-1)\n",
        "    anno = anno.permute(2,0,1).float()\n",
        "    anno_n = anno\n",
        "\n",
        "    return image_n, anno_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkeCei3xhIsH"
      },
      "source": [
        "t =40\n",
        "\n",
        "image_n, anno_n = Normal(img_train_order[t],anno_train_order[t])\n",
        "print(image_n.shape)\n",
        "print(anno_n.shape)\n",
        "print(index)\n",
        "print(img_train_order[t])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1iePHV2_rX5"
      },
      "source": [
        "#Test network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egCWKs3w_yeS"
      },
      "source": [
        "ny  = Tensor(image_n)\n",
        "img = ny.permute(0, 3, 1, 2)\n",
        "\n",
        "new = net(img)\n",
        "new = new.permute(0, 2, 3, 1)\n",
        "new = np.squeeze(new.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwdb0GG_q4dr"
      },
      "source": [
        "plt.figure(figsize=(38,38))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "im = np.squeeze(image_n)\n",
        "plt.imshow(im)\n",
        "plt.title('Normalized',fontsize=40)\n",
        "\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(new[:,:,1])\n",
        "plt.title('After U-net',fontsize=40)\n",
        "\n",
        "(_, atest) = cv2.threshold(new, 0.5, 1, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(atest[:,:,0])\n",
        "plt.title('Thresholded',fontsize=40)\n",
        "\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(anno_n[1,:,:])\n",
        "plt.title('True annotation',fontsize=40)\n",
        "\n",
        "\n",
        "(_ , n_cells) = label(atest[:,:,0], background=0, return_num=True, connectivity=1)\n",
        "print('Number of cells network processed image: ',n_cells)\n",
        "\n",
        "(_ , n_cells) = label(anno_n[1,:,:], background=0, return_num=True, connectivity=1)\n",
        "print('Number of cells annotation: ',n_cells)\n",
        "\n",
        "\n",
        "# OBSOBSOBS background is dim=0 and cells is dim=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwmQq7Siw_pL"
      },
      "source": [
        "#Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enxE8mO406eT"
      },
      "source": [
        "%%shell\n",
        "\n",
        "#We need scikit-image >0.18, this is currently not released as a pip package\n",
        "# To install it, do the following\n",
        "git clone https://github.com/scikit-image/scikit-image.git\n",
        "cd scikit-image\n",
        "pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1mM8lzqNDOc"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Deep/scikit-image/skimage')\n",
        "! ls\n",
        "import numpy as np\n",
        "from skimage.measure import label\n",
        "os.chdir('/content/drive/My Drive/Deep/scikit-image/skimage/metrics')\n",
        "from set_metrics import hausdorff_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZjQ4_eQtud4"
      },
      "source": [
        "import numpy as np\n",
        "from skimage.measure import label\n",
        "from skimage.metrics import hausdorff_distance\n",
        "\n",
        "class BinaryImageMetrics():\n",
        "    def __init__(self, y_true, y_pred):\n",
        "        #TODO: Add documentation\n",
        "        #TODO: implement Adjusted Rand Index and https://web.stanford.edu/class/cs273/scribing/2004/class8/scribe8.pdf\n",
        "        \n",
        "        # Numpy have the bug : ValueError: cannot set WRITEABLE flag to True of this array\n",
        "        # That is why we copy the array\n",
        "\n",
        "        # We force the predictions to be binary\n",
        "\n",
        "        y_true = np.copy(y_true)\n",
        "        y_pred = np.copy(y_pred)\n",
        "        y_true[y_true>0]=1\n",
        "        y_pred[y_pred>0] = 1\n",
        "        self.y_true= y_true\n",
        "        self.y_pred = y_pred\n",
        "        self.y_true_label = label(self.y_true)\n",
        "        self.y_pred_label = label(self.y_pred)\n",
        "\n",
        "    def get_count(self):\n",
        "        count_y_true = np.max(self.y_true_label)\n",
        "        count_y_pred = np.max(self.y_pred_label)\n",
        "        if count_y_pred == 0 or count_y_true == 0:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return min(count_y_true/count_y_pred, count_y_pred/count_y_true)\n",
        "\n",
        "    def get_f1(self, y_true=None, y_pred=None):\n",
        "        if y_true is None:\n",
        "            y_true = self.y_true\n",
        "        if y_pred is None:\n",
        "            y_pred = self.y_pred\n",
        "            \n",
        "        if y_true.max() == 0 and y_pred.max()==0:\n",
        "            return 0.0 \n",
        "            \n",
        "        tp, fp, _, fn = self.confusion_matrix(y_true, y_pred)\n",
        "        f1 = 2*tp / (2*tp +fp + fn)\n",
        "        return f1\n",
        "        \n",
        "    def get_iou(self, y_true=None, y_pred=None):\n",
        "        if y_true is None:\n",
        "            y_true = self.y_true\n",
        "        if y_pred is None:\n",
        "            y_pred = self.y_pred\n",
        "            \n",
        "        if y_true.max() == 0 and y_pred.max()==0:\n",
        "            return 0.0 \n",
        "            \n",
        "        tp, fp, _, fn = self.confusion_matrix(y_true, y_pred)\n",
        "        f1 = tp / (tp +fp + fn)\n",
        "        return f1\n",
        "\n",
        "    def get_hausdroff_dist(self, y_true=None, y_pred=None):\n",
        "        if y_true is None:\n",
        "            y_true = self.y_true\n",
        "        if y_pred is None:\n",
        "            y_pred = self.y_pred\n",
        "        \n",
        "        if y_true.max() == 0 or y_pred.max() == 0:\n",
        "            haus_dist = np.sqrt(y_true.shape[0]*y_true.shape[1])\n",
        "        else:\n",
        "            haus_dist = hausdorff_distance(y_true, y_pred)\n",
        "        return haus_dist\n",
        "\n",
        "    def get_iou_obj(self):\n",
        "        iou_obj = 0\n",
        "        total_y_pred = max(np.bincount(self.y_pred.flatten(),minlength=2)[1],1)\n",
        "        total_y_true = max(np.bincount(self.y_true.flatten(), minlength=2)[1],1)\n",
        "\n",
        "        for idx in range(1, self.y_true_label.max()+1):\n",
        "            gi, si = self._get_overlap(idx, return_rectangle=False, y_true_p_switch=False)\n",
        "            iou = (np.bincount(gi.flatten(), minlength=2)[1]/total_y_true)*self.get_iou(y_true=gi, y_pred=si)\n",
        "            iou_obj += iou\n",
        "\n",
        "        for idx in range(1, self.y_pred_label.max()+1):\n",
        "            si, gi = self._get_overlap(idx, return_rectangle=False, y_true_p_switch=True)\n",
        "            iou = (np.bincount(si.flatten(), minlength=2)[1]/total_y_pred)*self.get_iou(y_true=si, y_pred=gi)\n",
        "            iou_obj += iou\n",
        "\n",
        "        iou_obj /= 2\n",
        "\n",
        "        return iou_obj\n",
        "\n",
        "\n",
        "    def get_f1_obj(self):\n",
        "        f1_obj = 0\n",
        "        total_y_pred = max(np.bincount(self.y_pred.flatten(),minlength=2)[1],1)\n",
        "        total_y_true = max(np.bincount(self.y_true.flatten(), minlength=2)[1],1)\n",
        "\n",
        "        for idx in range(1, self.y_true_label.max()+1):\n",
        "            gi, si = self._get_overlap(idx, return_rectangle=False, y_true_p_switch=False)\n",
        "            f1 = (np.bincount(gi.flatten(), minlength=2)[1]/total_y_true)*self.get_f1(y_true=gi, y_pred=si)\n",
        "            f1_obj += f1\n",
        "\n",
        "        for idx in range(1, self.y_pred_label.max()+1):\n",
        "            si, gi = self._get_overlap(idx, return_rectangle=False, y_true_p_switch=True)\n",
        "            f1 = (np.bincount(si.flatten(), minlength=2)[1]/total_y_pred)*self.get_f1(y_true=si, y_pred=gi)\n",
        "            f1_obj += f1\n",
        "\n",
        "        f1_obj /= 2\n",
        "\n",
        "        return f1_obj\n",
        "\n",
        "\n",
        "    def get_hausdorff_obj_distance(self):\n",
        "        haus_dist_obj = 0\n",
        "        total_y_pred = np.bincount(self.y_pred.flatten(), minlength=2)[1]\n",
        "        total_y_true = np.bincount(self.y_true.flatten(), minlength=2)[1]\n",
        "        \n",
        "        if total_y_true == 0 or total_y_pred == 0:\n",
        "            # Note this conversion is different from\n",
        "            # https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/evaluation/\n",
        "            # But the Hausdorff distance is not defined for non-overlapping objects.\n",
        "            # Note that the distance of sqrt(h^2+w^2) is an arbary choice.\n",
        "            # 0.0 would skew the distance to much to the positive side, and\n",
        "            # infinite is misleading. \n",
        "            # In case both objects are empty, we return the max dist of y_true\n",
        "            return np.sqrt(self.y_true.shape[0]**2+self.y_true.shape[1]**2)\n",
        "\n",
        "        for idx in range(1, self.y_true_label.max()+1):\n",
        "            gi, si = self._get_overlap(idx, return_rectangle=True, y_true_p_switch=False)\n",
        "            if gi.max() == 0 or si.max() == 0:\n",
        "                haus_dist = ((gi.shape[0]*gi.shape[1])/total_y_true)*np.sqrt(gi.shape[0]**2+gi.shape[1]**2)\n",
        "            else:\n",
        "                haus_dist = (np.bincount(gi.flatten())[1]/total_y_true)*self.get_hausdroff_dist(y_true=gi, y_pred=si)\n",
        "            haus_dist_obj += haus_dist\n",
        "\n",
        "        for idx in range(1, self.y_pred_label.max()+1):\n",
        "            si, gi = self._get_overlap(idx, return_rectangle=True, y_true_p_switch=True)\n",
        "            if gi.max() == 0 or si.max() == 0:\n",
        "                haus_dist = ((si.shape[0]*si.shape[1])/total_y_pred)*np.sqrt(si.shape[0]**2+si.shape[1]**2)\n",
        "            else:\n",
        "                haus_dist = (np.bincount(si.flatten())[1]/total_y_pred)*self.get_hausdroff_dist(y_true=si, y_pred=gi)\n",
        "            haus_dist_obj += haus_dist\n",
        "\n",
        "        haus_dist_obj /= 2\n",
        "        return haus_dist_obj\n",
        "\n",
        "    def confusion_matrix(self, y_true, y_pred):\n",
        "        y_true= y_true.flatten()\n",
        "        y_pred = y_pred.flatten()*2\n",
        "        cm = y_true+y_pred\n",
        "        cm = np.bincount(cm, minlength=4)\n",
        "        tn, fp, fn, tp = cm\n",
        "        return tp, fp, tn, fn\n",
        "    \n",
        "    def _get_overlap(self, idx, return_rectangle=False, y_true_p_switch=False):\n",
        "        if y_true_p_switch:\n",
        "            y_pred = self.y_true_label\n",
        "            y_true = self.y_pred_label\n",
        "        else:\n",
        "            y_true = self.y_true_label\n",
        "            y_pred = self.y_pred_label\n",
        "\n",
        "        roi_y_true = np.argwhere(y_true == idx)\n",
        "        roi_y_pred = y_pred[roi_y_true[:,0],roi_y_true[:,1]]\n",
        "\n",
        "        # Finds max overlap, excluding background\n",
        "        matching_idx = np.bincount(roi_y_pred)\n",
        "        if len(matching_idx)<=1:\n",
        "            matching_idx = -1\n",
        "        else:\n",
        "            matching_idx = matching_idx[1:].argmax()+1\n",
        "        if return_rectangle:\n",
        "            bbox, _, _ = self._bounding_box(roi_y_true, at_origon=False)\n",
        "            roi_y_true = y_true[bbox[0]:bbox[2]+1,bbox[1]:bbox[3]+1]\n",
        "            roi_y_pred = y_pred[bbox[0]:bbox[2]+1,bbox[1]:bbox[3]+1]\n",
        "            roi_y_true =(roi_y_true==idx)*1\n",
        "\n",
        "        else:\n",
        "            roi_y_true = np.ones((len(roi_y_true)),dtype=int)\n",
        "        roi_y_pred = (roi_y_pred==matching_idx)*1\n",
        "        \n",
        "        return roi_y_true, roi_y_pred\n",
        "        \n",
        "    def _bounding_box(self, points, at_origon=False):\n",
        "        bbox = [min(points[:,0]), min(points[:,1]), max(points[:,0]), max(points[:,1])]\n",
        "        min_x = bbox[0]\n",
        "        min_y = bbox[1]\n",
        "        if at_origon:\n",
        "            bbox = [bbox[0] - min_x,\n",
        "                    bbox[1] - min_y,\n",
        "                    bbox[2] - min_x,\n",
        "                    bbox[3] - min_y]\n",
        "        return bbox, min_x, min_y\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brK54Hbpxbmz"
      },
      "source": [
        "#Test of function w. metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oTE0XRf4xmU"
      },
      "source": [
        "plt.figure(figsize=(21,7))\r\n",
        "\r\n",
        "i=1\r\n",
        "(image, true) = Normal(img_test_order[i], anno_test_order[i])\r\n",
        "    \r\n",
        "img = image.permute(0, 3, 1, 2)\r\n",
        "new = net(img)\r\n",
        "new = new.permute(0, 2, 3, 1)\r\n",
        "new = np.squeeze(new.detach().numpy())\r\n",
        "\r\n",
        "(_, pred) = cv2.threshold(new, 0.5, 1, cv2.THRESH_BINARY)\r\n",
        "pred = np.uint8(pred[:,:,0])\r\n",
        "true = np.uint8(true[1,:,:])\r\n",
        "\r\n",
        "metrics = BinaryImageMetrics(true, pred)\r\n",
        "\r\n",
        "plt.subplot(121)\r\n",
        "plt.imshow(pred, cmap='gray')\r\n",
        "\r\n",
        "plt.subplot(122)\r\n",
        "plt.imshow(true, cmap='gray')\r\n",
        "\r\n",
        "print(type(image))\r\n",
        "print(type(pred))\r\n",
        "\r\n",
        "print('F1-object',metrics.get_f1_obj())\r\n",
        "print('Hausdorff',metrics.get_hausdorff_obj_distance())\r\n",
        "print('iou',metrics.get_iou_obj())\r\n",
        "print('count',metrics.get_count())\r\n",
        "print('f1',metrics.get_f1())\r\n",
        "print(metrics.get_iou_obj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2WmdfPzy-5L"
      },
      "source": [
        "t = 5\r\n",
        "\r\n",
        "m = np.zeros((6,t))\r\n",
        "\r\n",
        "for i in range(0,t):\r\n",
        "  \r\n",
        "    (image, true) = Normal(img_test_order[i], anno_test_order[i])\r\n",
        "    \r\n",
        "    img = image.permute(0, 3, 1, 2)\r\n",
        "    new = net(img)\r\n",
        "    new = new.permute(0, 2, 3, 1)\r\n",
        "    new = np.squeeze(new.detach().numpy())\r\n",
        "\r\n",
        "    (_, pred) = cv2.threshold(new, 0.5, 1, cv2.THRESH_BINARY)\r\n",
        "    pred = np.uint8(pred[:,:,0])\r\n",
        "    true = np.uint8(true[1,:,:])\r\n",
        "\r\n",
        "    metrics = BinaryImageMetrics(true, pred)\r\n",
        "\r\n",
        "    m[0,i] = metrics.get_f1_obj()\r\n",
        "    m[1,i] = metrics.get_hausdorff_obj_distance()\r\n",
        "    m[2,i] = metrics.get_iou_obj()\r\n",
        "    m[3,i] = metrics.get_count()\r\n",
        "    m[4,i] = metrics.get_f1()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvlrqWWmkL-a"
      },
      "source": [
        "print('F1 object \"Dice\":  min:',m[0,:].min(),' median:',np.median(m[0,:]),'   mean:',np.mean(m[0,:]),' max:',m[0,:].max())\r\n",
        "print('Hausdorff \"shape\": min:',m[1,:].min(),'   median:',np.median(m[1,:]),'  mean:',np.mean(m[1,:]),' max:',m[1,:].max())\r\n",
        "print('IoU:               min:',m[2,:].min(),' median:',np.median(m[2,:]),'mean:',np.mean(m[2,:]),' max:',m[2,:].max())\r\n",
        "print('Count:             min:',m[3,:].min(),'median:',np.median(m[3,:]),'mean:',np.mean(m[3,:]),'max:',m[3,:].max())\r\n",
        "print('F1:                min:',m[4,:].min(),' median:',np.median(m[4,:]),' mean:',np.mean(m[4,:]),'max:',m[4,:].max())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}